{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_data = np.load(\"data/train/sup_data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(data, scale=255, reshape_dims=(200, 200, 1)):\n",
    "    \"\"\"Scales and reshapes image data.\"\"\"\n",
    "    data = data * scale\n",
    "    return np.array([image.reshape(reshape_dims) for image in data])\n",
    "\n",
    "def separate_dataset(data, labels):\n",
    "    \"\"\"Divides the data and the corresponding labels into 3 separate datasets, each one containing just a single phase\"\"\"\n",
    "    phases = [\"fe\", \"sk\", \"sp\"]\n",
    "    data = sup_data[\"data\"]\n",
    "    labels = sup_data[\"labels\"]\n",
    "    separated_dataset = {}\n",
    "\n",
    "    for label, phase in enumerate(phases): # 0-feromagnet, 1-skyrmion, 2-spiral\n",
    "        idxs = sup_data[\"labels\"] == label \n",
    "        separated_dataset[phase] = (data[idxs], labels[idxs])\n",
    "    \n",
    "    return separated_dataset\n",
    "\n",
    "\n",
    "def shuffle_and_split(data, labels, train_ratio, dev_ratio, random_seed=42):\n",
    "    \"\"\"Shuffles and splits the data into train, dev, and test sets.\"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.random.permutation(len(data))\n",
    "    data, labels = data[indices], labels[indices]\n",
    "    \n",
    "    train_stop = int(len(data) * train_ratio)\n",
    "    dev_stop = train_stop + int(len(data) * dev_ratio)\n",
    "    \n",
    "    train_data, train_labels = data[:train_stop], labels[:train_stop]\n",
    "    dev_data, dev_labels = data[train_stop:dev_stop], labels[train_stop:dev_stop]\n",
    "    test_data, test_labels = data[dev_stop:], labels[dev_stop:]\n",
    "    \n",
    "    return (train_data, train_labels), (dev_data, dev_labels), (test_data, test_labels)\n",
    "\n",
    "def train_dev_test_split(data, labels, train_ratio=0.8, dev_ratio=0.1):\n",
    "\n",
    "    for key, value in separate_dataset(data, labels).items():\n",
    "        train, dev, test = shuffle_and_split(*value, train_ratio, dev_ratio)\n",
    "        #TODO\n",
    "\n",
    "\n",
    "def save_dataset(filename, train_data, dev_data, test_data):\n",
    "    \"\"\"Saves the dataset into a `.npz` file.\"\"\"\n",
    "    np.savez(\n",
    "        filename,\n",
    "        train_images=train_data[0], train_labels=train_data[1],\n",
    "        dev_images=dev_data[0], dev_labels=dev_data[1],\n",
    "        test_images=test_data[0], test_labels=test_data[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = preprocess_images(sup_data[\"data\"])\n",
    "labels = sup_data[\"labels\"]\n",
    "\n",
    "separated_dataset = separate_dataset(data, labels)\n",
    "\n",
    "# Shuffle and split each category\n",
    "train_fe, dev_fe, test_fe = shuffle_and_split(*separated_dataset[\"fe\"], train_ratio, dev_ratio)\n",
    "train_sk, dev_sk, test_sk = shuffle_and_split(*separated_dataset[\"sk\"], train_ratio, dev_ratio)\n",
    "train_sp, dev_sp, test_sp = shuffle_and_split(*separated_dataset[\"sp\"], train_ratio, dev_ratio)\n",
    "\n",
    "# Combine train, dev, and test sets\n",
    "train_images = np.vstack([train_fe[0], train_sk[0], train_sp[0]])\n",
    "train_labels = np.hstack([train_fe[1], train_sk[1], train_sp[1]])\n",
    "\n",
    "dev_images = np.vstack([dev_fe[0], dev_sk[0], dev_sp[0]])\n",
    "dev_labels = np.hstack([dev_fe[1], dev_sk[1], dev_sp[1]])\n",
    "\n",
    "test_images = np.vstack([test_fe[0], test_sk[0], test_sp[0]])\n",
    "test_labels = np.hstack([test_fe[1], test_sk[1], test_sp[1]])\n",
    "\n",
    "# Shuffle the combined sets\n",
    "train_indices = np.random.permutation(len(train_images))\n",
    "dev_indices = np.random.permutation(len(dev_images))\n",
    "test_indices = np.random.permutation(len(test_images))\n",
    "\n",
    "train_images, train_labels = train_images[train_indices], train_labels[train_indices]\n",
    "dev_images, dev_labels = dev_images[dev_indices], dev_labels[dev_indices]\n",
    "test_images, test_labels = test_images[test_indices], test_labels[test_indices]\n",
    "\n",
    "# Preprocess images (scale and reshape)\n",
    "train_images = preprocess_images(train_images)\n",
    "dev_images = preprocess_images(dev_images)\n",
    "test_images = preprocess_images(test_images)\n",
    "\n",
    "# Save to file\n",
    "save_dataset(\n",
    "    'data/train/skyrmion_dataset2',\n",
    "    (train_images, train_labels),\n",
    "    (dev_images, dev_labels),\n",
    "    (test_images, test_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
